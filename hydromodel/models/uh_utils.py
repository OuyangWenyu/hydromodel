"""
Author: Zheng Zhang, supervised by Heng Lv
Date: 2025-07-08 18:30:00
LastEditTime: 2025-08-01 10:46:57
LastEditors: Wenyu Ouyang
Description: æ°´æ–‡æ¨¡å‹å·¥å…·æ¨¡å— -- åŒ…å«è„šæœ¬ä¸­å…¬å…±åŠŸèƒ½çš„å·¥å…·å‡½æ•°
FilePath: /hydromodel/hydromodel/models/uh_utils.py
Copyright (c) 2023-2026 Wenyu Ouyang. All rights reserved.
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from hydromodel.models.unit_hydrograph import uh_conv
# Use string constants directly instead of importing from consts
NET_RAIN = "P_eff"
OBS_FLOW = "Q_obs_eff"
DELTA_T_SECONDS = 10800.0  # 3.0 * 3600.0


# --- å›¾è¡¨é…ç½® ---
from hydromodel.models.common_utils import setup_matplotlib_chinese


def setup_matplotlib():
    """è®¾ç½®matplotlibçš„ä¸­æ–‡å­—ä½“å’Œæ ·å¼"""
    setup_matplotlib_chinese()
    plt.rcParams["mathtext.fontset"] = "stix"
    plt.rcParams["font.family"] = "sans-serif"


# --- è¯„ä¼°æŒ‡æ ‡è®¡ç®—åŠŸèƒ½ ---
def calculate_nse(Q_obs, Q_sim):
    """
    è®¡ç®—Nash-Sutcliffeæ•ˆç‡ç³»æ•°

    Args:
        Q_obs: è§‚æµ‹å¾„æµ
        Q_sim: æ¨¡æ‹Ÿå¾„æµ

    Returns:
        float: NSEå€¼
    """
    if len(Q_obs) == 0 or len(Q_sim) == 0 or len(Q_obs) != len(Q_sim):
        return np.nan

    mean_obs = np.mean(Q_obs)
    den_nse = np.sum((Q_obs - mean_obs) ** 2)

    if den_nse == 0:
        return 1.0 if np.allclose(Q_sim, Q_obs) else -np.inf
    else:
        return 1 - (np.sum((Q_obs - Q_sim) ** 2) / den_nse)


def calculate_volume_error(Q_obs, Q_sim):
    """
    è®¡ç®—æ´ªé‡ç›¸å¯¹è¯¯å·®

    Args:
        Q_obs: è§‚æµ‹å¾„æµ
        Q_sim: æ¨¡æ‹Ÿå¾„æµ

    Returns:
        float: æ´ªé‡ç›¸å¯¹è¯¯å·®(%)
    """
    vol_obs = np.sum(Q_obs) * DELTA_T_SECONDS
    vol_sim = np.sum(Q_sim) * DELTA_T_SECONDS

    if vol_obs > 1e-6:
        return ((vol_sim - vol_obs) / vol_obs) * 100.0
    else:
        return np.nan


def calculate_peak_error(Q_obs, Q_sim):
    """
    è®¡ç®—æ´ªå³°ç›¸å¯¹è¯¯å·®

    Args:
        Q_obs: è§‚æµ‹å¾„æµ
        Q_sim: æ¨¡æ‹Ÿå¾„æµ

    Returns:
        float: æ´ªå³°ç›¸å¯¹è¯¯å·®(%)
    """
    peak_obs = np.max(Q_obs)
    peak_sim = np.max(Q_sim)

    if peak_obs > 1e-6:
        return ((peak_sim - peak_obs) / peak_obs) * 100.0
    else:
        return np.nan


def evaluate_single_event(event_data, U_optimized, category_name=None):
    """
    è¯„ä¼°å•ä¸ªæ´ªæ°´äº‹ä»¶çš„æ€§èƒ½æŒ‡æ ‡

    Args:
        event_data: äº‹ä»¶æ•°æ®å­—å…¸
        U_optimized: ä¼˜åŒ–çš„å•ä½çº¿å‚æ•°
        category_name: ç±»åˆ«åç§°ï¼ˆå¯é€‰ï¼‰

    Returns:
        dict: åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸
    """
    P_event = event_data[NET_RAIN]
    Q_obs_event_full = event_data[OBS_FLOW]
    event_filename = os.path.basename(event_data["filepath"])

    # åˆå§‹åŒ–æŒ‡æ ‡
    result = {
        "æ–‡ä»¶å": event_filename,
        "NSE": np.nan,
        "æ´ªé‡ç›¸è¯¯(%)": np.nan,
        "æ´ªå³°ç›¸è¯¯(%)": np.nan,
    }

    # å¦‚æœæŒ‡å®šäº†ç±»åˆ«ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
    if category_name is not None:
        result["æ‰€å±ç±»åˆ«"] = category_name

    if U_optimized is not None:
        Q_sim_event_full = uh_conv(P_event, U_optimized, truncate=False)
        Q_sim_event_compare = Q_sim_event_full[: len(Q_obs_event_full)]

        if len(Q_obs_event_full) > 0 and len(Q_sim_event_compare) == len(
            Q_obs_event_full
        ):
            result["NSE"] = calculate_nse(
                Q_obs_event_full, Q_sim_event_compare
            )
            result["æ´ªé‡ç›¸è¯¯(%)"] = calculate_volume_error(
                Q_obs_event_full, Q_sim_event_compare
            )
            result["æ´ªå³°ç›¸è¯¯(%)"] = calculate_peak_error(
                Q_obs_event_full, Q_sim_event_compare
            )

    return result


# --- ç»“æœä¿å­˜å’Œè¾“å‡ºåŠŸèƒ½ ---
def save_results_to_csv(report_data, output_filename, sort_columns=None):
    """
    ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶

    Args:
        report_data: æŠ¥å‘Šæ•°æ®åˆ—è¡¨
        output_filename: è¾“å‡ºæ–‡ä»¶å
        sort_columns: æ’åºåˆ—ååˆ—è¡¨

    Returns:
        pd.DataFrame: æ’åºåçš„DataFrame
    """
    if not report_data:
        print("âŒ æ²¡æœ‰æ•°æ®å¯ä»¥ä¿å­˜")
        return None

    report_df = pd.DataFrame(report_data)

    # æ’åº
    if sort_columns:
        ascending = [True] * len(sort_columns)  # é»˜è®¤å‡åº
        if "NSE" in sort_columns:
            # NSEåˆ—æŒ‰é™åºæ’åˆ—
            nse_idx = sort_columns.index("NSE")
            ascending[nse_idx] = False
        report_df_sorted = report_df.sort_values(
            by=sort_columns, ascending=ascending
        ).reset_index(drop=True)
    else:
        report_df_sorted = report_df.copy()

    # ä¿å­˜æ–‡ä»¶
    try:
        # Use common utility for CSV saving
        from hydromodel.models.common_utils import save_dataframe_to_csv

        save_dataframe_to_csv(
            report_df_sorted,
            output_filename,
            encoding="utf-8-sig",
            float_format="%.4f",
        )
        print(f"\nâœ… è¯„ä¼°æŠ¥å‘Šå·²æˆåŠŸä¿å­˜åˆ°æ–‡ä»¶: {output_filename}")
    except Exception as e:
        print(f"\nâŒ ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶å¤±è´¥: {e}")

    return report_df_sorted


def print_report_preview(report_df_sorted, title="è¯„ä¼°æŠ¥å‘Šé¢„è§ˆ"):
    """
    æ‰“å°æŠ¥å‘Šé¢„è§ˆ

    Args:
        report_df_sorted: æ’åºåçš„DataFrame
        title: é¢„è§ˆæ ‡é¢˜
    """
    print(f"\nğŸ“Š --- {title} ---")
    pd.set_option("display.max_rows", 50)
    pd.set_option("display.width", 120)
    print(report_df_sorted)
    pd.reset_option("display.max_rows")
    pd.reset_option("display.width")


def print_category_statistics(report_df_sorted):
    """
    æ‰“å°å„ç±»åˆ«æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯

    Args:
        report_df_sorted: åŒ…å«ç±»åˆ«ä¿¡æ¯çš„DataFrame
    """
    if "æ‰€å±ç±»åˆ«" not in report_df_sorted.columns:
        return

    print("\nğŸ“ˆ --- å„ç±»åˆ«æ€§èƒ½ç»Ÿè®¡ ---")
    for category in ["small", "medium", "large"]:
        cat_data = report_df_sorted[report_df_sorted["æ‰€å±ç±»åˆ«"] == category]
        if len(cat_data) > 0:
            mean_nse = cat_data["NSE"].mean()
            mean_vol_err = cat_data["æ´ªé‡ç›¸è¯¯(%)"].mean()
            mean_peak_err = cat_data["æ´ªå³°ç›¸è¯¯(%)"].mean()
            print(f"ğŸ·ï¸ {category.capitalize()} ç±»åˆ« ({len(cat_data)} åœº):")
            print(f"   å¹³å‡NSE: {mean_nse:.4f}")
            print(f"   å¹³å‡æ´ªé‡è¯¯å·®: {mean_vol_err:.2f}%")
            print(f"   å¹³å‡æ´ªå³°è¯¯å·®: {mean_peak_err:.2f}%")


# --- æ´ªæ°´åˆ†ç±»åŠŸèƒ½ ---
def categorize_floods_by_peak(all_events_data):
    """
    æ ¹æ®æ´ªå³°å°†æ´ªæ°´äº‹ä»¶åˆ†ä¸ºä¸‰ç±»

    Args:
        all_events_data: åŒ…å«peak_obsçš„äº‹ä»¶æ•°æ®åˆ—è¡¨

    Returns:
        dict: åˆ†ç±»åçš„äº‹ä»¶å­—å…¸
        tuple: (threshold_low, threshold_high) åˆ†ç±»é˜ˆå€¼
    """
    event_peaks = [
        data["peak_obs"] for data in all_events_data if data["peak_obs"] > 0
    ]

    if not event_peaks:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ´ªå³°æ•°æ®")
        return None, (None, None)

    threshold_low = np.percentile(event_peaks, 33.3)  # 33.3%åˆ†ä½æ•°
    threshold_high = np.percentile(event_peaks, 66.6)  # 66.6%åˆ†ä½æ•°

    categorized_events = {"small": [], "medium": [], "large": []}

    for event_data in all_events_data:
        peak = event_data["peak_obs"]
        if peak <= threshold_low:
            categorized_events["small"].append(event_data)
        elif peak <= threshold_high:
            categorized_events["medium"].append(event_data)
        else:
            categorized_events["large"].append(event_data)

    return categorized_events, (threshold_low, threshold_high)
